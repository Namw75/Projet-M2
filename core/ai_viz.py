import openai
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import io
import os
from dotenv import load_dotenv
import chromadb
import uuid
from datetime import datetime

# Charger les variables d'environnement
load_dotenv('.env')

# Configuration OpenAI (nouvelle API v1.0+)
client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# ==== CONFIGURATION CHROMADB ====
def init_chroma_client():
    """Initialise le client ChromaDB"""
    try:
        # Client ChromaDB (persistant local par d√©faut)
        chroma_client = chromadb.PersistentClient(path="./chroma_db")
        
        # Cr√©er ou r√©cup√©rer une collection
        collection_name = "documents"
        try:
            collection = chroma_client.get_collection(name=collection_name)
            print(f"‚úÖ Collection '{collection_name}' r√©cup√©r√©e")
        except:
            # Cr√©er la collection si elle n'existe pas
            collection = chroma_client.create_collection(name=collection_name)
            print(f"‚úÖ Collection '{collection_name}' cr√©√©e")
            
        return chroma_client, collection
        
    except Exception as e:
        print(f"‚ùå Erreur ChromaDB : {e}")
        return None, None

def add_documents_to_chroma(collection, documents, metadatas=None, ids=None):
    """Ajoute des documents √† ChromaDB"""
    try:
        if ids is None:
            ids = [f"doc_{i}" for i in range(len(documents))]
        
        collection.add(
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        print(f"‚úÖ {len(documents)} documents ajout√©s √† ChromaDB")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ajout : {e}")

def populate_sample_documents(collection):
    """Ajoute des documents d'exemple pour tester ChromaDB"""
    sample_docs = [
        "Notre campagne marketing Q1 2024 a g√©n√©r√© 150% d'augmentation des ventes dans la r√©gion Nord",
        "Les retours clients montrent une satisfaction de 92% pour notre nouveau produit A",
        "Analyse des performances : les ventes en ligne ont augment√© de 80% par rapport √† l'ann√©e derni√®re",
        "Strat√©gie commerciale : focus sur les clients premium pour maximiser la marge",
        "Rapport trimestriel : croissance de 25% du chiffre d'affaires gr√¢ce aux campagnes digitales"
    ]
    
    metadatas = [
        {"type": "campagne", "periode": "Q1_2024", "region": "Nord"},
        {"type": "feedback", "produit": "A", "score": 92},
        {"type": "performance", "canal": "online", "croissance": 80},
        {"type": "strategie", "segment": "premium"},
        {"type": "rapport", "periode": "trimestriel", "croissance": 25}
    ]
    
    # V√©rifier si la collection est vide
    try:
        count = collection.count()
        if count == 0:
            add_documents_to_chroma(collection, sample_docs, metadatas)
            print(f"üìÑ {len(sample_docs)} documents d'exemple ajout√©s")
        else:
            print(f"üìÑ Collection contient d√©j√† {count} documents")
    except Exception as e:
        print(f"‚ùå Erreur lors du peuplement : {e}")

# ==== VECTOR SEARCH AVEC CHROMADB ====
def search_vector_db(query, collection):
    """Recherche s√©mantique dans ChromaDB selon votre logique"""
    # Recherche s√©mantique dans la collection ChromaDB
    try:
        # Recherche avec plus de r√©sultats et affichage debug
        results = collection.query(
            query_texts=[query], 
            n_results=10,  # Plus de r√©sultats
            include=['documents', 'metadatas', 'distances']
        )
        
        if results['documents'] and results['documents'][0]:
            # Filtrer les r√©sultats par pertinence (distance < 1.0 par exemple)
            documents = results['documents'][0]
            distances = results['distances'][0] if 'distances' in results else []
            metadatas = results['metadatas'][0] if 'metadatas' in results else []
            
            # Debug info
            print(f"üîç Recherche pour: '{query}'")
            print(f"üìÑ {len(documents)} r√©sultats trouv√©s")
            
            relevant_docs = []
            for i, (doc, distance, metadata) in enumerate(zip(documents, distances, metadatas)):
                print(f"  - Document {i+1} (distance: {distance:.3f}): {doc[:100]}...")
                # Seuil plus permissif - ChromaDB utilise la distance cosinus
                if distance < 2.0:  # Seuil plus permissif
                    relevant_docs.append(doc)
            
            if relevant_docs:
                combined_context = "\n\n".join(relevant_docs)
                print(f"‚úÖ {len(relevant_docs)} documents pertinents retenus")
                return combined_context
            else:
                # Si aucun document vraiment pertinent, prendre le meilleur quand m√™me
                if documents:
                    best_doc = documents[0]  # Le premier est le plus pertinent
                    print(f"‚ö†Ô∏è Aucun document tr√®s pertinent, utilisation du meilleur (distance: {distances[0]:.3f})")
                    return f"Document le plus proche trouv√© :\n{best_doc}"
                else:
                    return f"Aucun document trouv√© pour '{query}'"
        else:
            return "Aucun document trouv√© dans ChromaDB"
            
    except Exception as e:
        print(f"‚ùå Erreur ChromaDB : {e}")
        return f"Erreur ChromaDB: {e}"

# ==== SQL SEARCH ====
def search_sql_db(query, conn):
    """Recherche dans la base SQL avec g√©n√©ration automatique de requ√™tes"""
    try:
        from core.gpt_sql import get_sql_from_gpt
        sql = get_sql_from_gpt(query)
        print(f"üóÉÔ∏è SQL g√©n√©r√©e : {sql}")
        df = pd.read_sql_query(sql, conn)
        print(f"‚úÖ {len(df)} r√©sultats trouv√©s")
        return df, sql
    except ImportError:
        print("‚ö†Ô∏è Module gpt_sql non trouv√©, utilisation des donn√©es d'exemple")
        df = get_sample_data()
        sql = "-- Donn√©es d'exemple utilis√©es (module gpt_sql manquant)"
        return df, sql
    except Exception as e:
        print(f"‚ùå Erreur SQL : {e}")
        # En cas d'erreur, retourner des donn√©es d'exemple
        df = get_sample_data()
        sql = f"-- Erreur SQL: {e}, donn√©es d'exemple utilis√©es"
        return df, sql

def init_sql_connection():
    """Initialise la connexion √† la base de donn√©es SQLite"""
    import sqlite3
    try:
        conn = sqlite3.connect("bdd_clients.db")
        print("‚úÖ Connexion SQL √©tablie")
        return conn
    except Exception as e:
        print(f"‚ùå Erreur connexion SQL : {e}")
        return None

# ==== DONN√âES D'EXEMPLE (fallback) ====
def get_sample_data():
    """G√©n√®re des donn√©es d'exemple pour tester"""
    return pd.DataFrame({
        'mois': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],
        'ventes': [1000, 1200, 800, 1500, 1800, 1600],
        'region': ['Nord', 'Sud', 'Est', 'Ouest', 'Nord', 'Sud'],
        'produit': ['A', 'B', 'A', 'C', 'B', 'A']
    })

# ==== IA SELECTION & CODE GENERATION ====
def ai_generate_viz(user_request, df=None, vector_context=None):
    """G√©n√®re le code de visualisation avec l'IA selon les donn√©es disponibles"""
    # Pr√©pare le prompt selon les donn√©es disponibles
    head_df = df.head(5).to_string() if df is not None else ""
    context = f"\nVoici des informations issues de documents :\n{vector_context}\n" if vector_context else ""
    
    # Si on a uniquement du contexte vectoriel (pas de donn√©es tabulaires)
    if vector_context and (df is None or df.empty):
        # V√©rifier si le contexte contient vraiment des infos pertinentes
        if vector_context.startswith("Aucun document") or vector_context.startswith("Documents trouv√©s mais non pertinents") or vector_context.startswith("Erreur"):
            return f"# Je n'ai pas trouv√© d'informations sur '{user_request}' dans les documents upload√©s.\n# Veuillez v√©rifier que les documents pertinents ont √©t√© ajout√©s √† ChromaDB."
        
        prompt = f"""
        L'utilisateur te demande : {user_request}
        
        DOCUMENTS DISPONIBLES :
        {vector_context}
        
        INSTRUCTIONS CRITIQUES :
        - R√©ponds UNIQUEMENT en te basant sur les documents fournis ci-dessus
        - Si l'information n'est pas dans les documents, dis "Cette information n'est pas disponible dans les documents"
        - NE PAS inventer ou utiliser des connaissances g√©n√©rales
        - Sois pr√©cis et cite les √©l√©ments des documents
        - Si une visualisation est pertinente bas√©e sur les documents, g√©n√®re le code Python (matplotlib)
        - Sinon, fournis une r√©ponse textuelle sous forme de commentaires Python
        
        Format de r√©ponse :
        # === R√âPONSE BAS√âE SUR LES DOCUMENTS ===
        # [Ta r√©ponse ici bas√©e uniquement sur les documents]
        """
    else:
        # Prompt original pour la dataviz
        prompt = f"""
        L'utilisateur te demande : {user_request}
        {context}
        Voici les premi√®res lignes du dataframe (si pertinent) :
        {head_df}
        
        G√©n√®re uniquement le code Python (pandas/matplotlib) qui permet de visualiser la donn√©e de la fa√ßon la plus pertinente (ex: pie chart, bar plot, courbe, etc.). 
        Choisis le type de graphique le plus adapt√© √† la demande, pas de texte, seulement le code. 
        Suppose que le dataframe s'appelle df.
        Ne mets pas de ```python``` dans ta r√©ponse, juste le code pur.
        """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Tu es un assistant RAG (Retrieval-Augmented Generation). Tu r√©ponds UNIQUEMENT bas√© sur les documents fournis. Si l'info n'est pas dans les documents, tu le dis clairement."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.1  # Plus d√©terministe
        )
        
        # Ne garder QUE le code (enl√®ve les ```python √©ventuels)
        code = response.choices[0].message.content
        code = code.replace("```python", "").replace("```", "").strip()
        return code
        
    except Exception as e:
        return f"# Erreur lors de la g√©n√©ration : {e}"

# ==== EXECUTION DU CODE DE VIZ ====
def exec_and_display_plot(code, df):
    """Ex√©cute le code de visualisation et affiche le r√©sultat"""
    import matplotlib
    matplotlib.use('Agg')
    local_vars = {'df': df, 'plt': plt, 'pd': pd}
    try:
        exec(code, {}, local_vars)
        buf = io.BytesIO()
        plt.tight_layout()
        plt.savefig(buf, format="png", dpi=150, bbox_inches='tight')
        st.image(buf.getvalue())
        plt.close()
        return True
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du graphique : {e}")
        st.code(code, language="python")
        return False

# ==== PIPELINE PRINCIPAL - VOTRE LOGIQUE ====
def run_viz_pipeline(user_request, collection=None, sql_conn=None):
    """Votre pipeline principal avec routage IA intelligent"""
    
    # 1. On demande √† l'IA si la question vise plut√¥t la base SQL ou les docs PDF
    routing_prompt = f"""L'utilisateur demande : "{user_request}"
    S'il s'agit d'une donn√©e structur√©e (ex: clients, stats num√©riques), r√©ponds simplement "SQL".
    Si la r√©ponse se trouve dans des documents (PDF, texte libre, campagnes pass√©es...), r√©ponds simplement "VECTOR".
    Si les deux sont utiles, r√©ponds "BOTH".
    Ne donne aucune explication, juste un mot cl√©.
    """
    
    try:
        routing = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": routing_prompt}],
            max_tokens=10
        ).choices[0].message.content.strip().upper()
    except Exception as e:
        st.error(f"Erreur de routage IA : {e}")
        routing = "SQL"  # Fallback

    # 2. On r√©cup√®re la donn√©e selon le routage IA
    df, sql, vector_context = None, None, None
    
    if routing == "SQL":
        if sql_conn:
            df, sql = search_sql_db(user_request, sql_conn)
        else:
            df, sql = get_sample_data(), "-- Donn√©es d'exemple (pas de connexion SQL)"
            
    elif routing == "VECTOR":
        if collection:
            vector_context = search_vector_db(user_request, collection)
        else:
            vector_context = "Pas de connexion ChromaDB configur√©e. Donn√©es d'exemple utilis√©es."
            df = get_sample_data()
            
    elif routing == "BOTH":
        if sql_conn:
            df, sql = search_sql_db(user_request, sql_conn)
        else:
            df, sql = get_sample_data(), "-- Donn√©es d'exemple (pas de connexion SQL)"
            
        if collection:
            vector_context = search_vector_db(user_request, collection)
        else:
            vector_context = "Pas de connexion ChromaDB configur√©e."
    else:
        st.error("Impossible de d√©terminer la source de donn√©es √† utiliser.")
        return

    # 3. Afficher le routage choisi
    st.info(f"üß† Routage IA : {routing}")

    # 4. On g√©n√®re le code de visualisation pertinent
    code = ai_generate_viz(user_request, df=df, vector_context=vector_context)

    # 5. On ex√©cute le code (s'il y a un df, sinon afficher le contexte)
    if df is not None and not df.empty:
        st.markdown("### üìä Visualisation g√©n√©r√©e")
        success = exec_and_display_plot(code, df)
        
        if success:
            st.markdown("### üíª Code g√©n√©r√©")
            st.code(code, language="python")
            
        if sql and sql != "-- Donn√©es d'exemple":
            st.markdown("### üóÉÔ∏è SQL utilis√©e")
            st.code(sql, language="sql")
            
    elif vector_context:
        st.markdown("### üìÑ Contexte extrait des documents")
        
        # Afficher le contexte dans un expandeur pour ne pas encombrer
        with st.expander("üîç Documents trouv√©s", expanded=False):
            st.markdown(vector_context)
        
        st.markdown("### üß† Analyse Marketing IA")
        
        # Ex√©cuter le code d'analyse (m√™me si c'est du texte)
        if code.strip().startswith('#'):
            # Si c'est une analyse textuelle (commentaires)
            analysis_text = code.replace('# ', '').replace('#', '')
            st.markdown(analysis_text)
        else:
            # Si c'est du code de visualisation
            st.markdown("### üìä Visualisation conceptuelle")
            try:
                exec_and_display_plot(code, pd.DataFrame())  # DataFrame vide pour les sch√©mas conceptuels
            except:
                st.code(code, language="python")
                
        st.markdown("### üíª Code/Analyse g√©n√©r√©e")
        st.code(code, language="python")
        
    else:
        st.warning("Aucune donn√©e pertinente trouv√©e.")

# ==== INTERFACE STREAMLIT ====
def main():
    st.set_page_config(
        page_title="ü§ñ AI Data Visualization", 
        page_icon="ü§ñ",
        layout="wide"
    )
    
    st.title("ü§ñ AI Data Visualization")
    st.markdown("**G√©n√©rez des visualisations automatiquement avec l'IA !**")
    
    # V√©rifier la cl√© API
    if not client.api_key:
        st.error("üîë Cl√© OpenAI manquante ! Ajoutez OPENAI_API_KEY √† votre fichier .env")
        return

    # Configuration des connexions (sidebar)
    st.sidebar.header("‚öôÔ∏è Configuration")
    
    # Initialiser ChromaDB
    chroma_client, collection = init_chroma_client()
    
    # Initialiser la connexion SQL
    sql_conn = init_sql_connection()
    
    if collection:
        st.sidebar.success("‚úÖ ChromaDB connect√©")
        
        # Afficher le nombre de documents
        try:
            doc_count = collection.count()
            st.sidebar.info(f"üìÑ {doc_count} documents dans la base")
        except:
            st.sidebar.warning("‚ö†Ô∏è Impossible de compter les documents")
        
        # Section upload de documents
        st.sidebar.markdown("---")
        st.sidebar.subheader("üìÅ Upload de documents")
        
        uploaded_files = st.sidebar.file_uploader(
            "Ajoutez des documents √† ChromaDB",
            type=['txt', 'pdf', 'docx'],
            accept_multiple_files=True
        )
        
        # Traitement automatique des fichiers upload√©s
        if uploaded_files:
            for uploaded_file in uploaded_files:
                # V√©rifier si le fichier n'est pas d√©j√† trait√©
                file_key = f"processed_{uploaded_file.name}_{uploaded_file.size}"
                
                if file_key not in st.session_state:
                    with st.spinner(f"Traitement de {uploaded_file.name}..."):
                        # Traiter le fichier
                        content = process_uploaded_file(uploaded_file)
                        
                        if content.startswith("‚ùå"):
                            st.sidebar.error(content)
                        else:
                            # Ajouter automatiquement √† ChromaDB
                            chunks_added = add_document_to_chroma(collection, uploaded_file.name, content)
                            if chunks_added > 0:
                                st.sidebar.success(f"‚úÖ {uploaded_file.name} ajout√© ({chunks_added} chunks)")
                                st.session_state[file_key] = True
                                st.rerun()
                            else:
                                st.sidebar.error("‚ùå √âchec de l'ajout")
                else:
                    st.sidebar.info(f"üìÑ {uploaded_file.name} d√©j√† trait√©")
        
        # Bouton pour ajouter des exemples
        st.sidebar.markdown("---")
        if st.sidebar.button("üìù Ajouter des exemples"):
            populate_sample_documents(collection)
            st.sidebar.success("‚úÖ Documents d'exemple ajout√©s")
            st.rerun()
        
        # Bouton pour vider la base
        if st.sidebar.button("üóëÔ∏è Vider ChromaDB", type="secondary"):
            try:
                chroma_client.delete_collection(name="documents")
                chroma_client.create_collection(name="documents")
                st.sidebar.success("‚úÖ ChromaDB vid√©e")
                st.rerun()
            except Exception as e:
                st.sidebar.error(f"‚ùå Erreur : {e}")
                
    else:
        st.sidebar.error("‚ùå ChromaDB non disponible")
    
    # Note sur les connexions
    st.sidebar.markdown("---")
    
    # Statut des connexions
    st.sidebar.markdown("**üîó Connexions disponibles :**")
    st.sidebar.markdown("- ‚úÖ OpenAI GPT-4")
    
    if collection:
        doc_count = collection.count() if collection else 0
        st.sidebar.markdown(f"- ‚úÖ ChromaDB ({doc_count} docs)")
    else:
        st.sidebar.markdown("- ‚ùå ChromaDB")
        
    if sql_conn:
        # Tester la connexion SQL avec un count
        try:
            test_contacts = pd.read_sql_query("SELECT COUNT(*) as count FROM contacts", sql_conn)
            test_companies = pd.read_sql_query("SELECT COUNT(*) as count FROM companies", sql_conn)
            contacts_count = test_contacts['count'].iloc[0]
            companies_count = test_companies['count'].iloc[0]
            st.sidebar.markdown(f"- ‚úÖ Base SQL ({contacts_count} contacts, {companies_count} entreprises)")
        except Exception as e:
            st.sidebar.markdown("- ‚ö†Ô∏è Base SQL (erreur)")
    else:
        st.sidebar.markdown("- ‚ùå Base SQL")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    **üìÑ Formats support√©s :**
    - üìÑ Fichiers texte (.txt)
    - üìï PDF (.pdf) - n√©cessite PyPDF2
    - üìò Word (.docx) - n√©cessite python-docx
    """)
    
    # Interface principale
    st.markdown("---")
    
    user_request = st.text_input(
        "üéØ Que voulez-vous visualiser ?",
        placeholder="Ex: Graphique des ventes par mois, Analyse des campagnes marketing..."
    )
    
    col1, col2 = st.columns([1, 4])
    
    with col1:
        generate_btn = st.button("üöÄ G√©n√©rer", type="primary")
    
    if generate_btn and user_request:
        with st.spinner("ü§ñ Analyse et g√©n√©ration en cours..."):
            # Lancer votre pipeline principal avec la vraie connexion SQL
            run_viz_pipeline(user_request, collection, sql_conn)
            
    elif generate_btn:
        st.warning("‚ö†Ô∏è Veuillez saisir une demande !")
    
    # Exemples
    st.markdown("---")
    st.markdown("### üí° Exemples de demandes")
    
    examples = [
        "Graphique en barres des ventes par mois",
        "Analyse des campagnes marketing pass√©es", 
        "R√©partition des clients par r√©gion",
        "Tendance des performances trimestrielles"
    ]
    
    cols = st.columns(2)
    for i, example in enumerate(examples):
        cols[i % 2].button(f"üìä {example}", key=f"ex_{i}")

# ==== MODE TEST SIMPLE ====
def test_mode():
    """Mode test simple pour v√©rifier que tout fonctionne"""
    print("ü§ñ Test AI Data Visualization Pipeline")
    print("=" * 50)
    
    # V√©rifier la cl√© API
    if not client.api_key:
        print("‚ùå Cl√© OpenAI manquante ! Ajoutez OPENAI_API_KEY √† votre fichier .env")
        return
    
    # Initialiser ChromaDB pour le test
    print("üîß Initialisation ChromaDB...")
    chroma_client, collection = init_chroma_client()
    
    if collection:
        # Collection disponible pour les tests
        print(f"üìÑ Collection pr√™te avec {collection.count()} documents")
    
    # Test avec une demande marketing (pour tester VECTOR)
    user_request = "Que sais-tu de la strat√©gie marketing et des campagnes ?"
    print(f"üéØ Demande : {user_request}")
    
    # Test du pipeline complet
    print("ü§ñ Test du pipeline complet...")
    
    # Test du routage
    routing_prompt = f"""L'utilisateur demande : "{user_request}"
    S'il s'agit d'une donn√©e structur√©e (ex: clients, stats num√©riques), r√©ponds simplement "SQL".
    Si la r√©ponse se trouve dans des documents (PDF, texte libre, campagnes pass√©es...), r√©ponds simplement "VECTOR".
    Si les deux sont utiles, r√©ponds "BOTH".
    Ne donne aucune explication, juste un mot cl√©.
    """
    
    try:
        routing = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": routing_prompt}],
            max_tokens=10
        ).choices[0].message.content.strip().upper()
        print(f"üß† Routage choisi : {routing}")
    except Exception as e:
        print(f"‚ùå Erreur de routage : {e}")
        return
    
    # Test de la recherche vectorielle
    if routing == "VECTOR" and collection:
        print("üîç Test de la recherche vectorielle...")
        vector_context = search_vector_db(user_request, collection)
        print(f"üìÑ Contexte trouv√© : {vector_context[:200]}...")
        
        # G√©n√©rer l'analyse
        code = ai_generate_viz(user_request, df=None, vector_context=vector_context)
        print("\nüíª Analyse g√©n√©r√©e :")
        print("-" * 30)
        print(code)
        print("-" * 30)
        
    else:
        # Fallback sur des donn√©es d'exemple
        df = get_sample_data()
        code = ai_generate_viz(user_request, df=df)
        
        print("\nüíª Code g√©n√©r√© :")
        print("-" * 30)
        print(code)
        print("-" * 30)
        
        # Tester l'ex√©cution
        import matplotlib
        matplotlib.use('Agg')
        
        local_vars = {'df': df, 'plt': plt, 'pd': pd}
        
        try:
            exec(code, {}, local_vars)
            plt.tight_layout()
            plt.savefig('test_viz.png', dpi=150, bbox_inches='tight')
            plt.close()
            print("‚úÖ Graphique g√©n√©r√© et sauv√© dans 'test_viz.png'")
        except Exception as e:
            print(f"‚ùå Erreur lors de l'ex√©cution : {e}")
    
    print("‚úÖ Pipeline complet test√© avec succ√®s !")

# ==== FONCTIONS DE TRAITEMENT DE DOCUMENTS ====
def process_uploaded_file(uploaded_file):
    """Traite un fichier upload√© et retourne le texte"""
    try:
        if uploaded_file.type == "text/plain":
            # Fichier texte
            content = str(uploaded_file.read(), "utf-8")
            return content
        
        elif uploaded_file.type == "application/pdf":
            # Fichier PDF - n√©cessite PyPDF2 ou pymupdf
            try:
                import PyPDF2
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                return text
            except ImportError:
                return "‚ùå Installez PyPDF2 pour lire les PDFs : pip install PyPDF2"
        
        elif uploaded_file.type in ["application/vnd.openxmlformats-officedocument.wordprocessingml.document"]:
            # Fichier Word - n√©cessite python-docx
            try:
                import docx
                doc = docx.Document(uploaded_file)
                text = ""
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                return text
            except ImportError:
                return "‚ùå Installez python-docx pour lire les fichiers Word : pip install python-docx"
        
        else:
            return f"‚ùå Type de fichier non support√© : {uploaded_file.type}"
            
    except Exception as e:
        return f"‚ùå Erreur lors du traitement : {e}"

def chunk_text(text, chunk_size=1000, overlap=200):
    """D√©coupe le texte en chunks pour ChromaDB"""
    chunks = []
    text = text.strip()
    
    if len(text) <= chunk_size:
        return [text]
    
    start = 0
    while start < len(text):
        end = start + chunk_size
        
        # Essayer de couper √† la fin d'une phrase
        if end < len(text):
            # Chercher le dernier point ou saut de ligne
            last_period = text.rfind('.', start, end)
            last_newline = text.rfind('\n', start, end)
            cut_point = max(last_period, last_newline)
            
            if cut_point > start:
                end = cut_point + 1
        
        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)
        
        start = end - overlap
        
    return chunks

def add_document_to_chroma(collection, filename, content):
    """Ajoute un document d√©coup√© en chunks √† ChromaDB"""
    try:
        chunks = chunk_text(content)
        
        documents = []
        metadatas = []
        ids = []
        
        for i, chunk in enumerate(chunks):
            doc_id = f"{filename}_{uuid.uuid4().hex[:8]}_{i}"
            
            documents.append(chunk)
            metadatas.append({
                "filename": filename,
                "chunk_index": i,
                "total_chunks": len(chunks),
                "upload_date": datetime.now().isoformat(),
                "file_type": filename.split('.')[-1] if '.' in filename else "unknown"
            })
            ids.append(doc_id)
        
        collection.add(
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        
        return len(chunks)
        
    except Exception as e:
        st.error(f"Erreur lors de l'ajout √† ChromaDB : {e}")
        return 0

# ==== POINT D'ENTR√âE ====
if __name__ == "__main__":
    import sys
    
    # Si argument "test", lancer le mode test simple
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        test_mode()
    else:
        # Sinon lancer l'interface Streamlit
        main()

